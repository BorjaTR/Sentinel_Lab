import cocotb
from cocotb.clock import Clock
from cocotb.triggers import RisingEdge, Timer
import sys
import os
import random
import csv

class ExchangeModel:
    def __init__(self, num_users=1024):
        self.balances = {i: [1000000, 1000000] for i in range(num_users)}
        self.vault = [0, 0] # [USDC, GPU]
        self.vol_usdc = 0
        self.vol_gpu = 0

    def process(self, op, u_a, u_b, amt0, amt1):
        if u_a == u_b: return True

        bal_a = self.balances[u_a]
        bal_b = self.balances[u_b]

        # Fee Calculation (Bit Shift >> 11)
        fee0 = amt0 >> 11
        fee1 = amt1 >> 11

        if op == 0: # Transfer
            if bal_a[0] >= (amt0 + fee0):
                bal_a[0] -= (amt0 + fee0)
                bal_b[0] += amt0
                self.vault[0] += fee0
                self.vol_usdc += amt0
                return True
        elif op == 1: # Swap
            if bal_a[0] >= (amt0 + fee0) and bal_b[1] >= (amt1 + fee1):
                bal_a[0] -= (amt0 + fee0)
                bal_a[1] += amt1
                bal_b[0] += amt0
                bal_b[1] -= (amt1 + fee1)
                self.vault[0] += fee0
                self.vault[1] += fee1
                self.vol_usdc += amt0
                self.vol_gpu += amt1
                return True
        return False

@cocotb.test()
async def test_revenue_stream(dut):
    """
    Cocotb Test: Verify Hardware Against Golden Model
    """
    cocotb.fork(Clock(dut.clk, 10, units="ns").start())
    model = ExchangeModel()

    dut.rst_n.value = 0
    await RisingEdge(dut.clk)
    dut.rst_n.value = 1
    dut.s_valid.value = 0
    await RisingEdge(dut.clk)

    # Check if CSV scenario is provided
    scenario_file = os.environ.get("SCENARIO_FILE", None)
    transactions = []

    if scenario_file and os.path.exists(scenario_file):
        dut._log.info(f"ðŸš€ LOADING CSV SCENARIO: {scenario_file}")
        with open(scenario_file, 'r') as f:
            reader = csv.DictReader(f)
            for row in reader:
                transactions.append({
                    'op': int(row['opcode']),
                    'u_a': int(row['payer']),
                    'u_b': int(row['payee']),
                    'amt0': int(row['amount0']),
                    'amt1': int(row['amount1'])
                })
        dut._log.info(f"   -> Loaded {len(transactions)} transactions from CSV")
    else:
        # Random fuzzing mode
        dut._log.info("ðŸŽ² RANDOM FUZZING MODE (5,000 TXs)")
        for _ in range(5000):
            transactions.append({
                'op': random.randint(0, 1),
                'u_a': random.randint(0, 1023),
                'u_b': random.randint(0, 1023),
                'amt0': random.randint(2000, 5000),
                'amt1': random.randint(2000, 5000)
            })

    # Execute all transactions with time-series tracking
    start_time = cocotb.utils.get_sim_time('ns')
    batch_size = 500  # Track metrics every 500 transactions
    time_series = []
    tx_success_count = 0
    tx_failure_count = 0

    for idx, tx in enumerate(transactions):
        dut.s_opcode.value = tx['op']
        dut.s_user_a.value = tx['u_a']
        dut.s_user_b.value = tx['u_b']
        dut.s_amount_0.value = tx['amt0']
        dut.s_amount_1.value = tx['amt1']
        dut.s_valid.value = 1

        success = model.process(tx['op'], tx['u_a'], tx['u_b'], tx['amt0'], tx['amt1'])
        if success:
            tx_success_count += 1
        else:
            tx_failure_count += 1

        await RisingEdge(dut.clk)

        # Record time-series metrics every batch_size transactions
        if (idx + 1) % batch_size == 0:
            current_time = cocotb.utils.get_sim_time('ns')
            batch_duration = current_time - start_time
            batch_tps = (idx + 1) / batch_duration * 1000
            time_series.append({
                'batch': (idx + 1) // batch_size,
                'tx_count': idx + 1,
                'time_ns': current_time,
                'tps': batch_tps,
                'success_rate': tx_success_count / (idx + 1) * 100,
                'vault_usdc': int(dut.m_vault_usdc.value),
                'vault_gpu': int(dut.m_vault_gpu.value)
            })

    dut.s_valid.value = 0
    for _ in range(10): await RisingEdge(dut.clk)

    end_time = cocotb.utils.get_sim_time('ns')
    duration_ns = end_time - start_time
    tps = (len(transactions) / duration_ns) * 1_000

    # CHECK REVENUE VERIFICATION
    hw_vault_usdc = int(dut.m_vault_usdc.value)
    hw_vault_gpu  = int(dut.m_vault_gpu.value)

    dut._log.info(f"ðŸ’° Total Revenue: {hw_vault_usdc} USDC, {hw_vault_gpu} GPU Credits")

    assert hw_vault_usdc == model.vault[0], f"Vault USDC Mismatch! HW:{hw_vault_usdc} Mod:{model.vault[0]}"
    assert hw_vault_gpu == model.vault[1], f"Vault GPU Mismatch! HW:{hw_vault_gpu} Mod:{model.vault[1]}"

    # CHECK CONSERVATION (Users + Vault)
    total_usdc_hw = hw_vault_usdc
    total_gpu_hw = hw_vault_gpu

    for i in range(1024):
        raw = int(dut.portfolios[i].value)
        total_usdc_hw += raw & 0xFFFFFFFFFFFFFFFF
        total_gpu_hw += (raw >> 64) & 0xFFFFFFFFFFFFFFFF

    initial_usdc = 1024 * 1000000
    initial_gpu = 1024 * 1000000

    assert total_usdc_hw == initial_usdc, "Leak Detected in USDC!"
    assert total_gpu_hw == initial_gpu, "Leak Detected in GPU!"

    dut._log.info(f"âœ… SUCCESS: Processed {len(transactions)} TXs | {tps:.2f} Million TPS | No leaks detected.")

    # Write basic statistics to CSV
    os.makedirs("../logs", exist_ok=True)
    with open("../logs/sim_stats.csv", 'w') as f:
        f.write("metric,value\n")
        f.write(f"total_tx,{len(transactions)}\n")
        f.write(f"duration_ns,{duration_ns}\n")
        f.write(f"tps_million,{tps:.2f}\n")
        f.write(f"latency_cycles,1\n")
        f.write(f"rev_usdc,{hw_vault_usdc}\n")
        f.write(f"rev_gpu,{hw_vault_gpu}\n")
        f.write(f"vol_usdc,{model.vol_usdc}\n")
        f.write(f"vol_gpu,{model.vol_gpu}\n")

    # Write detailed analytics data for Phase 2 dashboard
    dut._log.info("ðŸ“Š Generating detailed analytics data...")

    # Write time-series data
    with open("../logs/time_series.csv", 'w') as f:
        f.write("batch,tx_count,time_ns,tps,success_rate,vault_usdc,vault_gpu\n")
        for point in time_series:
            f.write(f"{point['batch']},{point['tx_count']},{point['time_ns']},"
                   f"{point['tps']:.2f},{point['success_rate']:.2f},"
                   f"{point['vault_usdc']},{point['vault_gpu']}\n")

    # Collect final user portfolios from hardware
    user_portfolios = {}
    for i in range(1024):
        raw = int(dut.portfolios[i].value)
        usdc = raw & 0xFFFFFFFFFFFFFFFF
        gpu = (raw >> 64) & 0xFFFFFFFFFFFFFFFF
        total_value = usdc + gpu  # Simple valuation
        user_portfolios[i] = {'usdc': usdc, 'gpu': gpu, 'total': total_value}

    # Top 10 users by total value
    top_users = sorted(user_portfolios.items(), key=lambda x: x[1]['total'], reverse=True)[:10]
    with open("../logs/top_users.csv", 'w') as f:
        f.write("user_id,usdc_balance,gpu_balance,total_value\n")
        for user_id, balances in top_users:
            f.write(f"{user_id},{balances['usdc']},{balances['gpu']},{balances['total']}\n")

    # Transaction type distribution
    tx_types = {'transfer': 0, 'swap': 0}
    for tx in transactions:
        if tx['op'] == 0:
            tx_types['transfer'] += 1
        else:
            tx_types['swap'] += 1

    with open("../logs/tx_distribution.csv", 'w') as f:
        f.write("type,count\n")
        f.write(f"Transfer,{tx_types['transfer']}\n")
        f.write(f"Swap,{tx_types['swap']}\n")

    # Concentration metrics (whale detection)
    total_usdc_supply = sum(p['usdc'] for p in user_portfolios.values()) + hw_vault_usdc
    total_gpu_supply = sum(p['gpu'] for p in user_portfolios.values()) + hw_vault_gpu

    # Top 10 concentration
    top10_usdc = sum(balances['usdc'] for _, balances in top_users)
    top10_gpu = sum(balances['gpu'] for _, balances in top_users)

    with open("../logs/concentration.csv", 'w') as f:
        f.write("metric,value\n")
        f.write(f"top10_usdc_pct,{(top10_usdc / total_usdc_supply * 100):.2f}\n")
        f.write(f"top10_gpu_pct,{(top10_gpu / total_gpu_supply * 100):.2f}\n")
        f.write(f"gini_approx,0.45\n")  # Placeholder for Gini coefficient

    # Liquidity metrics
    active_users = sum(1 for p in user_portfolios.values() if p['total'] != 2000000)

    with open("../logs/liquidity.csv", 'w') as f:
        f.write("metric,value\n")
        f.write(f"active_users,{active_users}\n")
        f.write(f"total_users,1024\n")
        f.write(f"avg_usdc_balance,{total_usdc_supply / 1024:.2f}\n")
        f.write(f"avg_gpu_balance,{total_gpu_supply / 1024:.2f}\n")

    dut._log.info("âœ… Analytics data generation complete")
